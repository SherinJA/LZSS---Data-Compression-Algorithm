{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnGxShm+2mEhEri9mETODa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SherinJA/LZSS---Data-Compression-Algorithm/blob/master/LZSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# LZSS Compression\n",
        "def lzss_compress(text, search_size=7, lookahead_size=5):\n",
        "    search_buffer = \"\"\n",
        "    lookahead_buffer = text[:lookahead_size]\n",
        "    pos = lookahead_size\n",
        "    output = []\n",
        "    steps = []\n",
        "    i = 0\n",
        "\n",
        "    while lookahead_buffer:\n",
        "        # Find the longest match in the search buffer\n",
        "        longest_match_len = 0\n",
        "        longest_match_offset = 0\n",
        "\n",
        "        for j in range(len(search_buffer)):\n",
        "            match_len = 0\n",
        "            while (match_len < len(lookahead_buffer) and\n",
        "                   j + match_len < len(search_buffer) and\n",
        "                   search_buffer[j + match_len] == lookahead_buffer[match_len]):\n",
        "                match_len += 1\n",
        "\n",
        "            if match_len >= 1 and match_len > longest_match_len:\n",
        "                longest_match_len = match_len\n",
        "                longest_match_offset = len(search_buffer) - j  # Offset from end\n",
        "\n",
        "        # Decide output based on match\n",
        "        if longest_match_len >= 1:  # Only use pointers when they save space\n",
        "            output.append((1, (longest_match_offset, longest_match_len)))\n",
        "            matched_text = lookahead_buffer[:longest_match_len]\n",
        "        else:\n",
        "            output.append((0, lookahead_buffer[0]))\n",
        "            matched_text = lookahead_buffer[0]\n",
        "            longest_match_len = 1\n",
        "\n",
        "        # Record step\n",
        "        steps.append([i, search_buffer, lookahead_buffer,\n",
        "                      f\"({output[-1][0]}, {repr(output[-1][1]) if output[-1][0] == 0 else output[-1][1]})\"])\n",
        "\n",
        "        # Update buffers\n",
        "        search_buffer += matched_text\n",
        "        if len(search_buffer) > search_size:\n",
        "            search_buffer = search_buffer[-search_size:]\n",
        "\n",
        "        # Move forward in the lookahead buffer\n",
        "        lookahead_buffer = lookahead_buffer[longest_match_len:]\n",
        "\n",
        "        # Refill lookahead buffer\n",
        "        refill_length = min(longest_match_len, len(text) - pos)\n",
        "        if refill_length > 0:\n",
        "            lookahead_buffer += text[pos:pos + refill_length]\n",
        "            pos += refill_length\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print(\"Compression Steps:\")\n",
        "    print(tabulate(steps, headers=[\"Step\", \"Search Buffer\", \"Lookahead Buffer\", \"Output\"],\n",
        "                   tablefmt=\"grid\", stralign=\"left\"))\n",
        "    return output\n",
        "\n",
        "# LZSS Decompression\n",
        "def lzss_decompress(compressed, search_size=7):\n",
        "    buffer = \"\"\n",
        "    output = \"\"\n",
        "    steps = []\n",
        "\n",
        "    for i, (flag, value) in enumerate(compressed):\n",
        "        if flag == 0:  # Literal\n",
        "            buffer += value\n",
        "            output += value\n",
        "            if len(buffer) > search_size:\n",
        "                buffer = buffer[-search_size:]\n",
        "        else:  # Match\n",
        "            offset, length = value\n",
        "            # Handle the case where we need to copy from what we're currently generating\n",
        "            decoded = \"\"\n",
        "            for j in range(length):\n",
        "                if j < offset:\n",
        "                    char = buffer[len(buffer) - offset + j]\n",
        "                else:\n",
        "                    char = decoded[j - offset]\n",
        "                decoded += char\n",
        "\n",
        "            buffer += decoded\n",
        "            output += decoded\n",
        "            if len(buffer) > search_size:\n",
        "                buffer = buffer[-search_size:]\n",
        "\n",
        "        steps.append([i, buffer, f\"({flag}, {repr(value) if flag == 0 else value})\", output])\n",
        "\n",
        "    print(\"\\nDecompression Steps:\")\n",
        "    print(tabulate(steps, headers=[\"Step\", \"Buffer\", \"Input\", \"Output\"],\n",
        "                   tablefmt=\"grid\", stralign=\"left\"))\n",
        "    return output\n",
        "\n",
        "# Calculate size of original and compressed data\n",
        "def calculate_compression_stats(original_text, compressed_data):\n",
        "    # Calculate original size (1 byte per character)\n",
        "    original_size = len(original_text)\n",
        "\n",
        "    # Calculate compressed size\n",
        "    compressed_size = 0\n",
        "    for flag, value in compressed_data:\n",
        "        if flag == 0:  # Literal: 1 bit flag + 8 bits for character\n",
        "            compressed_size += 1 + 8\n",
        "        else:  # Pointer: 1 bit flag + bits for offset + bits for length\n",
        "            # Assuming 3 bits for offset (0-7) and 3 bits for length (0-7)\n",
        "            # This is an approximation; actual implementation may vary\n",
        "            compressed_size += 1 + 3 + 3\n",
        "\n",
        "    # Convert bits to bytes (round up to nearest byte)\n",
        "    compressed_size_bytes = (compressed_size + 7) // 8\n",
        "\n",
        "    # Calculate compression ratio\n",
        "    compression_ratio = original_size / compressed_size_bytes if compressed_size_bytes > 0 else 0\n",
        "\n",
        "    # Calculate space savings percentage\n",
        "    space_savings = (1 - (compressed_size_bytes / original_size)) * 100 if original_size > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"original_size_bytes\": original_size,\n",
        "        \"compressed_size_bits\": compressed_size,\n",
        "        \"compressed_size_bytes\": compressed_size_bytes,\n",
        "        \"compression_ratio\": compression_ratio,\n",
        "        \"space_savings_percentage\": space_savings\n",
        "    }\n",
        "\n",
        "# Test with the example string\n",
        "text = \"abracadabracabra\"\n",
        "print(f\"Original string: {text}\\n\")\n",
        "compressed = lzss_compress(text)\n",
        "print(f\"\\nCompressed output: {compressed}\")\n",
        "decompressed = lzss_decompress(compressed)\n",
        "print(f\"\\nDecompressed string: {decompressed}\")\n",
        "\n",
        "# Verify decompression was correct\n",
        "if text == decompressed:\n",
        "    print(\"\\nDecompression successful! Original and decompressed strings match.\")\n",
        "else:\n",
        "    print(\"\\nError: Decompression failed. Strings do not match.\")\n",
        "\n",
        "# Calculate and display compression statistics\n",
        "stats = calculate_compression_stats(text, compressed)\n",
        "\n",
        "print(\"\\nCompression Statistics:\")\n",
        "print(\"-----------------------\")\n",
        "print(f\"Original size: {stats['original_size_bytes']} bytes\")\n",
        "print(f\"Compressed size: {stats['compressed_size_bits']} bits ({stats['compressed_size_bytes']} bytes)\")\n",
        "print(f\"Compression ratio: {stats['compression_ratio']:.2f}:1\")\n",
        "print(f\"Space savings: {stats['space_savings_percentage']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlMHBdEmII2X",
        "outputId": "65706ce4-2c99-40cd-c655-c7ea8cfcb795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string: abracadabracabra\n",
            "\n",
            "Compression Steps:\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|   Step | Search Buffer   | Lookahead Buffer   | Output      |\n",
            "+========+=================+====================+=============+\n",
            "|      0 |                 | abrac              | (0, 'a')    |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      1 | a               | braca              | (0, 'b')    |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      2 | ab              | racad              | (0, 'r')    |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      3 | abr             | acada              | (1, (3, 1)) |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      4 | abra            | cadab              | (0, 'c')    |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      5 | abrac           | adabr              | (1, (5, 1)) |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      6 | abraca          | dabra              | (0, 'd')    |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      7 | abracad         | abrac              | (1, (7, 5)) |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "|      8 | adabrac         | abra               | (1, (5, 4)) |\n",
            "+--------+-----------------+--------------------+-------------+\n",
            "\n",
            "Compressed output: [(0, 'a'), (0, 'b'), (0, 'r'), (1, (3, 1)), (0, 'c'), (1, (5, 1)), (0, 'd'), (1, (7, 5)), (1, (5, 4))]\n",
            "\n",
            "Decompression Steps:\n",
            "+--------+----------+-------------+------------------+\n",
            "|   Step | Buffer   | Input       | Output           |\n",
            "+========+==========+=============+==================+\n",
            "|      0 | a        | (0, 'a')    | a                |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      1 | ab       | (0, 'b')    | ab               |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      2 | abr      | (0, 'r')    | abr              |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      3 | abra     | (1, (3, 1)) | abra             |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      4 | abrac    | (0, 'c')    | abrac            |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      5 | abraca   | (1, (5, 1)) | abraca           |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      6 | abracad  | (0, 'd')    | abracad          |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      7 | adabrac  | (1, (7, 5)) | abracadabrac     |\n",
            "+--------+----------+-------------+------------------+\n",
            "|      8 | racabra  | (1, (5, 4)) | abracadabracabra |\n",
            "+--------+----------+-------------+------------------+\n",
            "\n",
            "Decompressed string: abracadabracabra\n",
            "\n",
            "Decompression successful! Original and decompressed strings match.\n",
            "\n",
            "Compression Statistics:\n",
            "-----------------------\n",
            "Original size: 16 bytes\n",
            "Compressed size: 73 bits (10 bytes)\n",
            "Compression ratio: 1.60:1\n",
            "Space savings: 37.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from tabulate import tabulate\n",
        "\n",
        "# LZSS Compression Function (copied from the original script)\n",
        "def lzss_compress(text, search_size=7, lookahead_size=5):\n",
        "    search_buffer = \"\"\n",
        "    lookahead_buffer = text[:lookahead_size]\n",
        "    pos = lookahead_size\n",
        "    output = []\n",
        "    steps = []\n",
        "    i = 0\n",
        "\n",
        "    while lookahead_buffer:\n",
        "        # Find the longest match in the search buffer\n",
        "        longest_match_len = 0\n",
        "        longest_match_offset = 0\n",
        "\n",
        "        for j in range(len(search_buffer)):\n",
        "            match_len = 0\n",
        "            while (match_len < len(lookahead_buffer) and\n",
        "                   j + match_len < len(search_buffer) and\n",
        "                   search_buffer[j + match_len] == lookahead_buffer[match_len]):\n",
        "                match_len += 1\n",
        "\n",
        "            if match_len >= 1 and match_len > longest_match_len:\n",
        "                longest_match_len = match_len\n",
        "                longest_match_offset = len(search_buffer) - j  # Offset from end\n",
        "\n",
        "        # Decide output based on match\n",
        "        if longest_match_len >= 1:  # Only use pointers when they save space\n",
        "            output.append((1, (longest_match_offset, longest_match_len)))\n",
        "            matched_text = lookahead_buffer[:longest_match_len]\n",
        "        else:\n",
        "            output.append((0, lookahead_buffer[0]))\n",
        "            matched_text = lookahead_buffer[0]\n",
        "            longest_match_len = 1\n",
        "\n",
        "        # Record step\n",
        "        steps.append([i, search_buffer, lookahead_buffer,\n",
        "                      f\"({output[-1][0]}, {repr(output[-1][1]) if output[-1][0] == 0 else output[-1][1]})\"])\n",
        "\n",
        "        # Update buffers\n",
        "        search_buffer += matched_text\n",
        "        if len(search_buffer) > search_size:\n",
        "            search_buffer = search_buffer[-search_size:]\n",
        "\n",
        "        # Move forward in the lookahead buffer\n",
        "        lookahead_buffer = lookahead_buffer[longest_match_len:]\n",
        "\n",
        "        # Refill lookahead buffer\n",
        "        refill_length = min(longest_match_len, len(text) - pos)\n",
        "        if refill_length > 0:\n",
        "            lookahead_buffer += text[pos:pos + refill_length]\n",
        "            pos += refill_length\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return output, steps\n",
        "\n",
        "# LZSS Decompression Function\n",
        "def lzss_decompress(compressed, search_size=7):\n",
        "    buffer = \"\"\n",
        "    output = \"\"\n",
        "    steps = []\n",
        "\n",
        "    for i, (flag, value) in enumerate(compressed):\n",
        "        if flag == 0:  # Literal\n",
        "            buffer += value\n",
        "            output += value\n",
        "            if len(buffer) > search_size:\n",
        "                buffer = buffer[-search_size:]\n",
        "        else:  # Match\n",
        "            offset, length = value\n",
        "            # Handle the case where we need to copy from what we're currently generating\n",
        "            decoded = \"\"\n",
        "            for j in range(length):\n",
        "                if j < offset:\n",
        "                    char = buffer[len(buffer) - offset + j]\n",
        "                else:\n",
        "                    char = decoded[j - offset]\n",
        "                decoded += char\n",
        "\n",
        "            buffer += decoded\n",
        "            output += decoded\n",
        "            if len(buffer) > search_size:\n",
        "                buffer = buffer[-search_size:]\n",
        "\n",
        "        steps.append([i, buffer, f\"({flag}, {repr(value) if flag == 0 else value})\", output])\n",
        "\n",
        "    return output, steps\n",
        "\n",
        "# Calculate compression statistics\n",
        "def calculate_compression_stats(original_text, compressed_data):\n",
        "    # Calculate original size (1 byte per character)\n",
        "    original_size = len(original_text)\n",
        "\n",
        "    # Calculate compressed size\n",
        "    compressed_size = 0\n",
        "    for flag, value in compressed_data:\n",
        "        if flag == 0:  # Literal: 1 bit flag + 8 bits for character\n",
        "            compressed_size += 1 + 8\n",
        "        else:  # Pointer: 1 bit flag + bits for offset + bits for length\n",
        "            compressed_size += 1 + 3 + 3\n",
        "\n",
        "    # Convert bits to bytes (round up to nearest byte)\n",
        "    compressed_size_bytes = (compressed_size + 7) // 8\n",
        "\n",
        "    # Calculate compression ratio\n",
        "    compression_ratio = original_size / compressed_size_bytes if compressed_size_bytes > 0 else 0\n",
        "\n",
        "    # Calculate space savings percentage\n",
        "    space_savings = (1 - (compressed_size_bytes / original_size)) * 100 if original_size > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"original_size_bytes\": original_size,\n",
        "        \"compressed_size_bits\": compressed_size,\n",
        "        \"compressed_size_bytes\": compressed_size_bytes,\n",
        "        \"compression_ratio\": compression_ratio,\n",
        "        \"space_savings_percentage\": space_savings\n",
        "    }\n",
        "\n",
        "# Streamlit App\n",
        "def main():\n",
        "    st.title(\"LZSS Compression Demonstration\")\n",
        "\n",
        "    # Input section\n",
        "    st.header(\"Input\")\n",
        "    input_text = st.text_input(\"Enter text to compress:\", \"abracadabracabra\")\n",
        "    search_size = st.slider(\"Search Buffer Size\", min_value=1, max_value=15, value=7)\n",
        "    lookahead_size = st.slider(\"Lookahead Buffer Size\", min_value=1, max_value=10, value=5)\n",
        "\n",
        "    # Compression button\n",
        "    if st.button(\"Compress\"):\n",
        "        # Perform compression\n",
        "        compressed, compression_steps = lzss_compress(input_text, search_size, lookahead_size)\n",
        "\n",
        "        # Decompress to verify\n",
        "        decompressed, decompression_steps = lzss_decompress(compressed)\n",
        "\n",
        "        # Calculate statistics\n",
        "        stats = calculate_compression_stats(input_text, compressed)\n",
        "\n",
        "        # Display results\n",
        "        st.header(\"Compression Results\")\n",
        "\n",
        "        # Original Text\n",
        "        st.subheader(\"Original Text\")\n",
        "        st.text(input_text)\n",
        "\n",
        "        # Compressed Output\n",
        "        st.subheader(\"Compressed Output\")\n",
        "        st.write(compressed)\n",
        "\n",
        "        # Decompressed Text\n",
        "        st.subheader(\"Decompressed Text\")\n",
        "        st.text(decompressed)\n",
        "\n",
        "        # Verification\n",
        "        if input_text == decompressed:\n",
        "            st.success(\"Decompression successful! Original and decompressed strings match.\")\n",
        "        else:\n",
        "            st.error(\"Error: Decompression failed. Strings do not match.\")\n",
        "\n",
        "        # Compression Statistics\n",
        "        st.subheader(\"Compression Statistics\")\n",
        "        st.write(f\"Original size: {stats['original_size_bytes']} bytes\")\n",
        "        st.write(f\"Compressed size: {stats['compressed_size_bits']} bits ({stats['compressed_size_bytes']} bytes)\")\n",
        "        st.write(f\"Compression ratio: {stats['compression_ratio']:.2f}:1\")\n",
        "        st.write(f\"Space savings: {stats['space_savings_percentage']:.2f}%\")\n",
        "\n",
        "        # Compression Steps (Detailed View)\n",
        "        st.subheader(\"Compression Steps\")\n",
        "        compression_steps_df = pd.DataFrame(compression_steps,\n",
        "                                            columns=[\"Step\", \"Search Buffer\", \"Lookahead Buffer\", \"Output\"])\n",
        "        st.dataframe(compression_steps_df)\n",
        "\n",
        "        # Decompression Steps (Detailed View)\n",
        "        st.subheader(\"Decompression Steps\")\n",
        "        decompression_steps_df = pd.DataFrame(decompression_steps,\n",
        "                                              columns=[\"Step\", \"Buffer\", \"Input\", \"Output\"])\n",
        "        st.dataframe(decompression_steps_df)\n",
        "\n",
        "# Additional imports for Streamlit\n",
        "import pandas as pd\n",
        "\n",
        "# Run the Streamlit app\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aHMR4ril_-4",
        "outputId": "04e56966-e5a5-480b-c3fe-bf99deadb993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-26 04:01:03.966 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.095 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-03-26 04:01:04.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.104 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.105 Session state does not function when running a script without `streamlit run`\n",
            "2025-03-26 04:01:04.106 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.109 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.110 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.111 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.112 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.113 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-26 04:01:04.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install streamlit tabulate pandas\n",
        "\n",
        "# Save the Streamlit app to a file\n",
        "with open('lzss_compression_app.py', 'w') as f:\n",
        "    f.write('''\n",
        "# [Paste the entire contents of the artifact here]\n",
        "''')\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run lzss_compression_app.py & npx localtunnel 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyCmGlHsmDkB",
        "outputId": "2a75372f-cb7d-4379-b432-f63a78583f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.108.187:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0KUsage: lt --port [num] <options>\n",
            "\n",
            "Options:\n",
            "  -p, --port                Internal HTTP server port                 [required]\n",
            "  -h, --host                Upstream server providing forwarding\n",
            "                                             [default: \"https://localtunnel.me\"]\n",
            "  -s, --subdomain           Request this subdomain\n",
            "  -l, --local-host          Tunnel traffic to this host instead of localhost,\n",
            "                            override Host header to this host\n",
            "      --local-https         Tunnel traffic to a local HTTPS server     [boolean]\n",
            "      --local-cert          Path to certificate PEM file for local HTTPS server\n",
            "      --local-key           Path to certificate key file for local HTTPS server\n",
            "      --local-ca            Path to certificate authority file for self-signed\n",
            "                            certificates\n",
            "      --allow-invalid-cert  Disable certificate checks for your local HTTPS\n",
            "                            server (ignore cert/key/ca options)        [boolean]\n",
            "  -o, --open                Opens the tunnel URL in your browser\n",
            "      --print-requests      Print basic request info                   [boolean]\n",
            "      --help                Show this help and exit                    [boolean]\n",
            "      --version             Show version number                        [boolean]\n",
            "\n",
            "Missing required argument: port\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBDpMp-8nQyX",
        "outputId": "9ce917c0-7174-4f44-dea1-59ad1e50ecd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.1.66.247\n",
            "10.1.66.247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "HDoq1eJHnYS2",
        "outputId": "1aaad5e4-5a81-4426-956e-5d0d17a7cf45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "added 22 packages in 863ms\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "FC7pF6QknZzn",
        "outputId": "b659ab49-8187-43ca-843b-eea12e16193d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.86.108.187\n"
          ]
        }
      ]
    }
  ]
}